{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPY4opRvalHR4daJrq/qHwE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OzcanCevik/OzcanCevik/blob/main/roboflow_vericekme_modele%C4%9Fitme_otomatik.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Br1948LQiEZA"
      },
      "outputs": [],
      "source": [
        "!pip install roboflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from roboflow import Roboflow"
      ],
      "metadata": {
        "id": "Z6zRMGYTib3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = Roboflow(api_key=\"fKsVVo3aUM2HEy2TkeFA\")"
      ],
      "metadata": {
        "id": "6qBMbq1ZieXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "project = rf.workspace(\"wordalpha02\").project(\"wordalpha2-gkrmd\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4AE_RsrirFd",
        "outputId": "dc16b0ad-4def-4f8b-f57c-22b16aaa5ee7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "version = project.version(3)"
      ],
      "metadata": {
        "id": "S0bXPN8DiwtG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = version.download(\"yolov8\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuuTMUC8izVy",
        "outputId": "8ce56d69-0518-435c-9782-20a75193a2ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dependency ultralytics==8.0.196 is required but found version=8.2.100, to fix: `pip install ultralytics==8.0.196`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in wordalpha2-3 to yolov8:: 100%|██████████| 49232/49232 [00:03<00:00, 13791.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to wordalpha2-3 in yolov8:: 100%|██████████| 29744/29744 [00:03<00:00, 7721.37it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "Vz6gH2rNi_y_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zW55AsgzjCta",
        "outputId": "217215dc-1455-4f60-abf5-8537c98af26d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO(\"yolov8n.pt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtikHK-5jHQ_",
        "outputId": "a93b6540-fdc5-4b87-b0fb-c1087cd30e8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6.25M/6.25M [00:00<00:00, 23.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "# İndirilen ZIP dosyasının yolunu belirtin\n",
        "zip_path = \"/content/wordalpha2-1/roboflow.zip\"\n",
        "output_dir = \"/content/dataset\"\n"
      ],
      "metadata": {
        "id": "1dQxPr0YDlXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Klasörü sil runs\n",
        "shutil.rmtree('/content/runs')\n"
      ],
      "metadata": {
        "id": "jWS1wGqyM0WS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train(data='/content/wordalpha2-3/data.yaml', epochs=50, imgsz=640)"
      ],
      "metadata": {
        "id": "SVEKVvxXjL4U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c52dead-468a-4415-bc57-b740d2403006"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.100 🚀 Python-3.10.12 torch-2.4.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/content/yolov8n.pt, data=/content/wordalpha2-3/data.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Overriding model.yaml nc=80 with nc=62\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    763402  ultralytics.nn.modules.head.Detect           [62, [64, 128, 256]]          \n",
            "Model summary: 225 layers, 3,022,938 parameters, 3,022,922 gradients, 8.3 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/wordalpha2-3/train/labels.cache... 14251 images, 9 backgrounds, 21 corrupt: 100%|██████████| 14272/14272 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/wordalpha2-3/train/images/1389-00_jpg.rf.47ba28364a39399a11fe990468860a3e.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/wordalpha2-3/train/images/1389-00_jpg.rf.d704f1fa07ad1c94e870258512a6c7b9.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/wordalpha2-3/train/images/177-48_jpg.rf.e4c1723ad96f5d823baf11a14e80b240.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/wordalpha2-3/train/images/205-00_jpg.rf.5bd2c252a1e498db4f1b248db631d7d3.jpg: ignoring corrupt image/label: image size (15, 7) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/wordalpha2-3/train/images/205-00_jpg.rf.64236e4842a11de5749db303fe9b7e07.jpg: ignoring corrupt image/label: image size (15, 7) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/wordalpha2-3/train/images/205-00_jpg.rf.685c0738bd68f7b1333498ae97f85eed.jpg: ignoring corrupt image/label: image size (15, 7) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/wordalpha2-3/train/images/207-60_jpg.rf.672af7d1a425455092eb4280c320f55b.jpg: ignoring corrupt image/label: image size (13, 9) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/wordalpha2-3/train/images/207-60_jpg.rf.9e5980f733c0bfe8c129f909dcb19215.jpg: ignoring corrupt image/label: image size (13, 9) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/wordalpha2-3/train/images/207-60_jpg.rf.fc241b5a1da337914a17e5daab8b4c3f.jpg: ignoring corrupt image/label: image size (13, 9) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/wordalpha2-3/train/images/260-15_jpg.rf.200bcfba123b430d9d3b23527ec79989.jpg: ignoring corrupt image/label: image size (15, 7) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/wordalpha2-3/train/images/260-15_jpg.rf.6617b1368c524853161e1abcb4316253.jpg: ignoring corrupt image/label: image size (15, 7) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/wordalpha2-3/train/images/260-15_jpg.rf.a8cc12cb94447c5e0b5b04fcb8b2c284.jpg: ignoring corrupt image/label: image size (15, 7) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/wordalpha2-3/train/images/281-72_jpg.rf.06fc5e78271cb9b0907329a3afba1514.jpg: ignoring corrupt image/label: image size (15, 8) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/wordalpha2-3/train/images/281-72_jpg.rf.dcdb291b40ae0357654000bb8919e9f7.jpg: ignoring corrupt image/label: image size (15, 8) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/wordalpha2-3/train/images/281-72_jpg.rf.dec0928dff2d008584096a9d069fbfab.jpg: ignoring corrupt image/label: image size (15, 8) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/wordalpha2-3/train/images/327-32_jpg.rf.1aa5108a92c1bb4c76c1f278752e8006.jpg: ignoring corrupt image/label: image size (15, 7) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/wordalpha2-3/train/images/327-32_jpg.rf.7579712524acf358f7197afc0e1a10a5.jpg: ignoring corrupt image/label: image size (15, 7) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/wordalpha2-3/train/images/327-32_jpg.rf.8389cf9bb4a61b4abeb22e170d350c2c.jpg: ignoring corrupt image/label: image size (15, 7) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/wordalpha2-3/train/images/345-37_jpg.rf.b8d00d916fdcec233b583503cb488e1a.jpg: ignoring corrupt image/label: image size (14, 7) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/wordalpha2-3/train/images/345-37_jpg.rf.d7ad1fb342b4259291fa85c8dc12de6d.jpg: ignoring corrupt image/label: image size (14, 7) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/wordalpha2-3/train/images/345-37_jpg.rf.e8d86fe684d8f0e796b37c46df245243.jpg: ignoring corrupt image/label: image size (14, 7) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/wordalpha2-3/train/images/610-33_jpg.rf.4ee54e3482a0bf58d5a0fcabfdddcc11.jpg: ignoring corrupt image/label: image size (13, 9) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/wordalpha2-3/train/images/610-33_jpg.rf.631ce04ea06aa57cec976304b4850189.jpg: ignoring corrupt image/label: image size (13, 9) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/wordalpha2-3/train/images/610-33_jpg.rf.dd8c1fc2400e244fade54f202e24e86b.jpg: ignoring corrupt image/label: image size (13, 9) <10 pixels\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/wordalpha2-3/valid/labels.cache... 547 images, 4 backgrounds, 4 corrupt: 100%|██████████| 551/551 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/wordalpha2-3/valid/images/412-84_jpg.rf.55ef3851260186b04972388d39690c3d.jpg: ignoring corrupt image/label: image size (15, 7) <10 pixels\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/wordalpha2-3/valid/images/452-85_jpg.rf.360fdb4d69d910cf969a091df17c283a.jpg: ignoring corrupt image/label: image size (15, 8) <10 pixels\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/wordalpha2-3/valid/images/453-17_jpg.rf.f804471b6cdbc14b737b8fb90d8402ba.jpg: ignoring corrupt image/label: image size (15, 8) <10 pixels\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/wordalpha2-3/valid/images/51-15_jpg.rf.8f62aa8cc3ab04d56753f31aad0a2e44.jpg: ignoring corrupt image/label: image size (15, 8) <10 pixels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/50      2.58G     0.8899      2.793      1.113        139        640: 100%|██████████| 891/891 [04:43<00:00,  3.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:04<00:00,  3.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        547       3186      0.806      0.774      0.841      0.707\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/50      2.45G      0.828      1.108      1.102        135        640: 100%|██████████| 891/891 [04:22<00:00,  3.39it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:04<00:00,  3.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        547       3186      0.908      0.915      0.938      0.789\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/50      2.43G     0.8217     0.9532      1.075        180        640: 100%|██████████| 891/891 [04:31<00:00,  3.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:04<00:00,  4.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        547       3186      0.921      0.922      0.937      0.801\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/50      2.44G     0.8094     0.8743      1.062        142        640: 100%|██████████| 891/891 [04:34<00:00,  3.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:04<00:00,  3.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        547       3186      0.942      0.941      0.961       0.82\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/50      2.44G     0.7819     0.7825      1.047        188        640:  96%|█████████▌| 851/891 [04:12<00:15,  2.60it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO  # Gerekli kütüphaneyi içe aktar\n",
        "\n",
        "# Modelinizi yükleyin\n",
        "model = YOLO('/content/yolov8n.pt')  # Model dosyanızın yolu\n",
        "\n",
        "# Eğitim devam ettirme\n",
        "try:\n",
        "    model.train(data='/content/wordalpha2-3/data.yaml',\n",
        "                epochs=50,  # Toplam dönem sayısı\n",
        "                imgsz=640,\n",
        "                resume='/content/runs/detect/train/weights/last.pt')  # Kaldığınız yerden devam edin\n",
        "except AssertionError as e:\n",
        "    print(f\"Hata: {e}\")  # Hata mesajını yazdır\n"
      ],
      "metadata": {
        "id": "A0VvzLxoLNYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Model dosyasının varlığını kontrol et\n",
        "if os.path.exists('/content/runs/detect/train/weights/best.pt'):\n",
        "    print(\"Model dosyası mevcut.\")\n",
        "else:\n",
        "    print(\"Model dosyası mevcut değil. Lütfen yolu kontrol edin.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTsBLLNOKd5r",
        "outputId": "4735fb54-f55f-4924-8e56-b779aa837214"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model dosyası mevcut.\n"
          ]
        }
      ]
    }
  ]
}